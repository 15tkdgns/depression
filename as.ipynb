{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1fc53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from datetime import datetime\n",
    "from preprocess.data_loader import load_data\n",
    "from preprocess.preprocessing import preprocess\n",
    "from preprocess.feature_selection import select_features\n",
    "from models.dnn import build_dnn\n",
    "from models.traditional import train_traditional_models\n",
    "from evaluations.evaluation import evaluate_model\n",
    "from configs import config\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141d580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna objective: DNN 하이퍼파라미터 자동탐색 함수\n",
    "def objective_dnn(trial, X_train, y_train):\n",
    "    # 아키텍처(은닉층 구성)와 드롭아웃 비율 탐색\n",
    "    layers = trial.suggest_categorical(\n",
    "        'layers',\n",
    "        [(512, 256), (1024, 512, 256), (1024, 512, 256, 128)]\n",
    "    )\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "\n",
    "    # 후보 파라미터로 모델 생성 및 훈련\n",
    "    model = build_dnn(X_train.shape[1], layers, dropout=dropout, optimizer='Adam')\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=30,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # 검증 정확도 최대값 기준으로 탐색\n",
    "    return max(history.history['val_accuracy'])\n",
    "\n",
    "\n",
    "# Optuna objective: 랜덤포레스트 하이퍼파라미터 자동탐색 함수\n",
    "def objective_rf(trial, X_train, y_train):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    # 탐색할 파라미터 공간\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10)\n",
    "    }\n",
    "    rf = RandomForestClassifier(**params, random_state=config.SEED)\n",
    "    # 교차검증(3-fold) 평균 정확도로 평가\n",
    "    return cross_val_score(rf, X_train, y_train, cv=3, scoring='accuracy').mean()\n",
    "\n",
    "\n",
    "# Optuna objective: TabNet 하이퍼파라미터 자동탐색 함수\n",
    "def objective_tabnet(trial, X_train, y_train, X_valid, y_valid):\n",
    "    # 주요 하이퍼파라미터 범위 정의\n",
    "    params = {\n",
    "        'n_d': trial.suggest_int('n_d', 8, 64),\n",
    "        'n_a': trial.suggest_int('n_a', 8, 64),\n",
    "        'n_steps': trial.suggest_int('n_steps', 3, 10),\n",
    "        'gamma': trial.suggest_float('gamma', 1.0, 2.0),\n",
    "        'lambda_sparse': trial.suggest_float('lambda_sparse', 1e-5, 1e-1, log=True)\n",
    "    }\n",
    "    clf = TabNetClassifier(**params, seed=config.SEED)\n",
    "    clf.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_valid, y_valid)],\n",
    "        patience=10,\n",
    "        max_epochs=100,\n",
    "        batch_size=1024\n",
    "    )\n",
    "    preds = clf.predict(X_valid)\n",
    "    # 정확도 기준\n",
    "    return evaluate_model(y_valid, preds)['accuracy']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(search_time_minutes=5):\n",
    "    # 1. 데이터 로딩 및 기본 전처리\n",
    "    df_original = load_data(config.DATA_PATH)\n",
    "    df, numeric_cols, categorical_cols = preprocess(df_original)\n",
    "\n",
    "    # 2. 타겟 레이블 그룹화\n",
    "    df['mh_PHQ_S_grouped'] = df['mh_PHQ_S'].apply(lambda x: 0 if x <= 4 else 1 if x <= 9 else 2)\n",
    "    X = df.drop(['mh_PHQ_S', 'mh_PHQ_S_grouped'], axis=1)\n",
    "    y = df['mh_PHQ_S_grouped']\n",
    "\n",
    "    # 3. 결측치 평균 대치\n",
    "    X = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(X), columns=X.columns)\n",
    "    # 4. 학습/테스트 분할\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=config.SEED)\n",
    "    # 5. 피처 셀렉션\n",
    "    X_train_selected, selected_features, selector = select_features(X_train, y_train, config.SELECTED_FEATURES)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    # 6. 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "    X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "    # 7. 탐색 시간(초) 설정\n",
    "    timeout = search_time_minutes * 60\n",
    "\n",
    "    # 8. Optuna로 각 모델별 하이퍼파라미터 탐색 (탐색시간=timeout)\n",
    "    studies = {}\n",
    "    for model_name, objective in [('DNN', objective_dnn), ('RandomForest', objective_rf)]:\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(lambda trial: objective(trial, X_train_scaled, y_train), timeout=timeout)\n",
    "        studies[model_name] = study\n",
    "\n",
    "    # TabNet은 float32로 입력!\n",
    "    tabnet_study = optuna.create_study(direction='maximize')\n",
    "    tabnet_study.optimize(\n",
    "        lambda trial: objective_tabnet(\n",
    "            trial,\n",
    "            X_train_scaled.astype(np.float32), y_train.values,\n",
    "            X_test_scaled.astype(np.float32), y_test.values\n",
    "        ),\n",
    "        timeout=timeout\n",
    "    )\n",
    "    studies['TabNet'] = tabnet_study\n",
    "\n",
    "    # 9. 모델별 최적 파라미터로 최종 학습/테스트 및 성능 기록\n",
    "    model_records = []\n",
    "    param_records = []\n",
    "\n",
    "    for model_name, study in studies.items():\n",
    "        best_params = study.best_params\n",
    "        if model_name == 'DNN':\n",
    "            model = build_dnn(\n",
    "                X_train_scaled.shape[1],\n",
    "                best_params['layers'],\n",
    "                dropout=best_params['dropout']\n",
    "            )\n",
    "            model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
    "            y_pred = model.predict(X_test_scaled).argmax(axis=1)\n",
    "        elif model_name == 'RandomForest':\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "            model = RandomForestClassifier(**best_params, random_state=config.SEED)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "        elif model_name == 'TabNet':\n",
    "            model = TabNetClassifier(**best_params, seed=config.SEED)\n",
    "            model.fit(X_train_scaled.astype(np.float32), y_train.values, max_epochs=100, batch_size=1024)\n",
    "            y_pred = model.predict(X_test_scaled.astype(np.float32))\n",
    "\n",
    "        # 평가 함수(정확도, 정밀도, 재현율, F1 등)\n",
    "        metrics = evaluate_model(y_test, y_pred)\n",
    "\n",
    "        model_records.append({\n",
    "            'Model': model_name,\n",
    "            **metrics,\n",
    "        })\n",
    "\n",
    "        param_records.append({\n",
    "            'Model': model_name,\n",
    "            'Hyperparameters': best_params\n",
    "        })\n",
    "\n",
    "    # 10. 결과를 reports/ 폴더에 엑셀로 저장 (자동 폴더 생성)\n",
    "    now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "    excel_filename = f\"reports/{now}_detailed_model_report.xlsx\"\n",
    "    with pd.ExcelWriter(excel_filename, engine='xlsxwriter') as writer:\n",
    "        pd.DataFrame(model_records).to_excel(writer, sheet_name='Performance', index=False)\n",
    "        pd.DataFrame(param_records).to_excel(writer, sheet_name='Hyperparameters', index=False)\n",
    "\n",
    "    print(f\"Detailed report saved to '{excel_filename}'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # search_time_minutes: 모델별 탐색시간(분), 원하는 대로 조정\n",
    "    main(search_time_minutes=5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
